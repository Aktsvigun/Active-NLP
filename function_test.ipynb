{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f44a6410310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parse():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'conll'\n",
    "        self.result_path = 'neural_ner/results'\n",
    "        self.usemodel = 'CNN_BiLSTM_CRF'\n",
    "        self.worddim = 100\n",
    "        self.pretrnd = 'wordvectors/glove.6B.100d.txt'\n",
    "        self.reload = 0\n",
    "        self.num_epochs = 10\n",
    "\n",
    "opt=Parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import codecs\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "START_TAG = '<START>'\n",
    "STOP_TAG = '<STOP>'\n",
    "\n",
    "def get_name(parameters):\n",
    "    \"\"\"\n",
    "    Generate a model name from its parameters.\n",
    "    \"\"\"\n",
    "    l = []\n",
    "    for k, v in parameters.items():\n",
    "        if type(v) is str and \"/\" in v:\n",
    "            l.append((k, v[::-1][:v[::-1].index('/')][::-1]))\n",
    "        else:\n",
    "            l.append((k, v))\n",
    "    name = \",\".join([\"%s=%s\" % (k, str(v).replace(',', '')) for k, v in l])\n",
    "    return \"\".join(i for i in name if i not in \"\\/:*?<>|\")\n",
    "\n",
    "\n",
    "def set_values(name, param, pretrained):\n",
    "    \"\"\"\n",
    "    Initialize a network parameter with pretrained values.\n",
    "    We check that sizes are compatible.\n",
    "    \"\"\"\n",
    "    param_value = param.get_value()\n",
    "    if pretrained.size != param_value.size:\n",
    "        raise Exception(\n",
    "            \"Size mismatch for parameter %s. Expected %i, found %i.\"\n",
    "            % (name, param_value.size, pretrained.size)\n",
    "        )\n",
    "    param.set_value(np.reshape(\n",
    "        pretrained, param_value.shape).astype(np.float32))\n",
    "\n",
    "\n",
    "def create_dico(item_list):\n",
    "    \"\"\"\n",
    "    Create a dictionary of items from a list of list of items.\n",
    "    \"\"\"\n",
    "    assert type(item_list) is list\n",
    "    dico = {}\n",
    "    for items in item_list:\n",
    "        for item in items:\n",
    "            if item not in dico:\n",
    "                dico[item] = 1\n",
    "            else:\n",
    "                dico[item] += 1\n",
    "    return dico\n",
    "\n",
    "\n",
    "def create_mapping(dico):\n",
    "    \"\"\"\n",
    "    Create a mapping (item to ID / ID to item) from a dictionary.\n",
    "    Items are ordered by decreasing frequency.\n",
    "    \"\"\"\n",
    "    sorted_items = sorted(dico.items(), key=lambda x: (-x[1], x[0]))\n",
    "    id_to_item = {i: v[0] for i, v in enumerate(sorted_items)}\n",
    "    item_to_id = {v: k for k, v in id_to_item.items()}\n",
    "    return item_to_id, id_to_item\n",
    "\n",
    "\n",
    "def zero_digits(s):\n",
    "    \"\"\"\n",
    "    Replace every digit in a string by a zero.\n",
    "    \"\"\"\n",
    "    return re.sub('\\d', '0', s)\n",
    "\n",
    "\n",
    "def iob2(tags):\n",
    "    \"\"\"\n",
    "    Check that tags have a valid IOB format.\n",
    "    Tags in IOB1 format are converted to IOB2.\n",
    "    \"\"\"\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag == 'O':\n",
    "            continue\n",
    "        split = tag.split('-')\n",
    "        if len(split) != 2 or split[0] not in ['I', 'B']:\n",
    "            return False\n",
    "        if split[0] == 'B':\n",
    "            continue\n",
    "        elif i == 0 or tags[i - 1] == 'O':  # conversion IOB1 to IOB2\n",
    "            tags[i] = 'B' + tag[1:]\n",
    "        elif tags[i - 1][1:] == tag[1:]:\n",
    "            continue\n",
    "        else:  # conversion IOB1 to IOB2\n",
    "            tags[i] = 'B' + tag[1:]\n",
    "    return True\n",
    "\n",
    "\n",
    "def iob_iobes(tags):\n",
    "    \"\"\"\n",
    "    IOB -> IOBES\n",
    "    \"\"\"\n",
    "    new_tags = []\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag == 'O':\n",
    "            new_tags.append(tag)\n",
    "        elif tag.split('-')[0] == 'B':\n",
    "            if i + 1 != len(tags) and \\\n",
    "               tags[i + 1].split('-')[0] == 'I':\n",
    "                new_tags.append(tag)\n",
    "            else:\n",
    "                new_tags.append(tag.replace('B-', 'S-'))\n",
    "        elif tag.split('-')[0] == 'I':\n",
    "            if i + 1 < len(tags) and \\\n",
    "                    tags[i + 1].split('-')[0] == 'I':\n",
    "                new_tags.append(tag)\n",
    "            else:\n",
    "                new_tags.append(tag.replace('I-', 'E-'))\n",
    "        else:\n",
    "            raise Exception('Invalid IOB format!')\n",
    "    return new_tags\n",
    "\n",
    "\n",
    "def iobes_iob(tags):\n",
    "    \"\"\"\n",
    "    IOBES -> IOB\n",
    "    \"\"\"\n",
    "    new_tags = []\n",
    "    for i, tag in enumerate(tags):\n",
    "        if tag.split('-')[0] == 'B':\n",
    "            new_tags.append(tag)\n",
    "        elif tag.split('-')[0] == 'I':\n",
    "            new_tags.append(tag)\n",
    "        elif tag.split('-')[0] == 'S':\n",
    "            new_tags.append(tag.replace('S-', 'B-'))\n",
    "        elif tag.split('-')[0] == 'E':\n",
    "            new_tags.append(tag.replace('E-', 'I-'))\n",
    "        elif tag.split('-')[0] == 'O':\n",
    "            new_tags.append(tag)\n",
    "        else:\n",
    "            raise Exception('Invalid format!')\n",
    "    return new_tags\n",
    "\n",
    "\n",
    "def insert_singletons(words, singletons, p=0.5):\n",
    "    \"\"\"\n",
    "    Replace singletons by the unknown word with a probability p.\n",
    "    \"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word in singletons and np.random.uniform() < p:\n",
    "            new_words.append(0)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "def pad_word_chars(words):\n",
    "    \"\"\"\n",
    "    Pad the characters of the words in a sentence.\n",
    "    Input:\n",
    "        - list of lists of ints (list of words, a word being a list of char indexes)\n",
    "    Output:\n",
    "        - padded list of lists of ints\n",
    "        - padded list of lists of ints (where chars are reversed)\n",
    "        - list of ints corresponding to the index of the last character of each word\n",
    "    \"\"\"\n",
    "    max_length = max([len(word) for word in words])\n",
    "    char_for = []\n",
    "    char_rev = []\n",
    "    char_pos = []\n",
    "    for word in words:\n",
    "        padding = [0] * (max_length - len(word))\n",
    "        char_for.append(word + padding)\n",
    "        char_rev.append(word[::-1] + padding)\n",
    "        char_pos.append(len(word) - 1)\n",
    "    return char_for, char_rev, char_pos\n",
    "\n",
    "\n",
    "def create_input(data, parameters, add_label, singletons=None):\n",
    "    \"\"\"\n",
    "    Take sentence data and return an input for\n",
    "    the training or the evaluation function.\n",
    "    \"\"\"\n",
    "    words = data['words']\n",
    "    chars = data['chars']\n",
    "    if singletons is not None:\n",
    "        words = insert_singletons(words, singletons)\n",
    "    if parameters['cap_dim']:\n",
    "        caps = data['caps']\n",
    "    char_for, char_rev, char_pos = pad_word_chars(chars)\n",
    "    input = []\n",
    "    if parameters['word_dim']:\n",
    "        input.append(words)\n",
    "    if parameters['char_dim']:\n",
    "        input.append(char_for)\n",
    "        if parameters['char_bidirect']:\n",
    "            input.append(char_rev)\n",
    "        input.append(char_pos)\n",
    "    if parameters['cap_dim']:\n",
    "        input.append(caps)\n",
    "    if add_label:\n",
    "        input.append(data['tags'])\n",
    "    return input\n",
    "\n",
    "def char_mapping(sentences):\n",
    "    \"\"\"\n",
    "    Create a dictionary and mapping of characters, sorted by frequency.\n",
    "    \"\"\"\n",
    "    chars = [\"\".join([w[0] for w in s]) for s in sentences]\n",
    "    dico = create_dico(chars)\n",
    "    dico['<PAD>'] = 10000000\n",
    "    # dico[';'] = 0\n",
    "    char_to_id, id_to_char = create_mapping(dico)\n",
    "    print(\"Found %i unique characters\" % len(dico))\n",
    "    return dico, char_to_id, id_to_char\n",
    "\n",
    "\n",
    "def tag_mapping(sentences):\n",
    "    \"\"\"\n",
    "    Create a dictionary and a mapping of tags, sorted by frequency.\n",
    "    \"\"\"\n",
    "    tags = [[word[-1] for word in s] for s in sentences]\n",
    "    dico = create_dico(tags)\n",
    "    dico[START_TAG] = -1\n",
    "    dico[STOP_TAG] = -2\n",
    "    tag_to_id, id_to_tag = create_mapping(dico)\n",
    "    print(\"Found %i unique named entity tags\" % len(dico))\n",
    "    return dico, tag_to_id, id_to_tag\n",
    "\n",
    "\n",
    "def cap_feature(s):\n",
    "    \"\"\"\n",
    "    Capitalization feature:\n",
    "    0 = low caps\n",
    "    1 = all caps\n",
    "    2 = first letter caps\n",
    "    3 = one capital (not first letter)\n",
    "    \"\"\"\n",
    "    if s.lower() == s:\n",
    "        return 0\n",
    "    elif s.upper() == s:\n",
    "        return 1\n",
    "    elif s[0].upper() == s[0]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def prepare_sentence(str_words, word_to_id, char_to_id, lower=False):\n",
    "    \"\"\"\n",
    "    Prepare a sentence for evaluation.\n",
    "    \"\"\"\n",
    "    def f(x): return x.lower() if lower else x\n",
    "    words = [word_to_id[f(w) if f(w) in word_to_id else '<UNK>']\n",
    "             for w in str_words]\n",
    "    chars = [[char_to_id[c] for c in w if c in char_to_id]\n",
    "             for w in str_words]\n",
    "    caps = [cap_feature(w) for w in str_words]\n",
    "    return {\n",
    "        'str_words': str_words,\n",
    "        'words': words,\n",
    "        'chars': chars,\n",
    "        'caps': caps\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_dataset(sentences, word_to_id, char_to_id, tag_to_id, lower=True):\n",
    "    \"\"\"\n",
    "    Prepare the dataset. Return a list of lists of dictionaries containing:\n",
    "        - word indexes\n",
    "        - word char indexes\n",
    "        - tag indexes\n",
    "    \"\"\"\n",
    "    def f(x): return x.lower() if lower else x\n",
    "    data = []\n",
    "    for s in sentences:\n",
    "        str_words = [w[0] for w in s]\n",
    "        words = [word_to_id[f(w) if f(w) in word_to_id else '<UNK>']\n",
    "                 for w in str_words]\n",
    "        # Skip characters that are not in the training set\n",
    "        chars = [[char_to_id[c] for c in w if c in char_to_id]\n",
    "                 for w in str_words]\n",
    "        caps = [cap_feature(w) for w in str_words]\n",
    "        tags = [tag_to_id[w[-1]] for w in s]\n",
    "        data.append({\n",
    "            'str_words': str_words,\n",
    "            'words': words,\n",
    "            'chars': chars,\n",
    "            'caps': caps,\n",
    "            'tags': tags,\n",
    "        })\n",
    "    return data\n",
    "\n",
    "\n",
    "def augment_with_pretrained(dictionary, ext_emb_path, words):\n",
    "    \"\"\"\n",
    "    Augment the dictionary with words that have a pretrained embedding.\n",
    "    If `words` is None, we add every word that has a pretrained embedding\n",
    "    to the dictionary, otherwise, we only add the words that are given by\n",
    "    `words` (typically the words in the development and test sets.)\n",
    "    \"\"\"\n",
    "    print('Loading pretrained embeddings from %s...' % ext_emb_path)\n",
    "    assert os.path.isfile(ext_emb_path)\n",
    "\n",
    "    # Load pretrained embeddings from file\n",
    "    pretrained = set([\n",
    "        line.rstrip().split()[0].strip()\n",
    "        for line in codecs.open(ext_emb_path, 'r', 'utf-8')\n",
    "        if len(ext_emb_path) > 0\n",
    "    ])\n",
    "    \n",
    "    if words is None:\n",
    "        for word in pretrained:\n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = 0\n",
    "    else:\n",
    "        for word in words:\n",
    "            if any(x in pretrained for x in [\n",
    "                word,\n",
    "                word.lower(),\n",
    "                re.sub('\\d', '0', word.lower())\n",
    "            ]) and word not in dictionary:\n",
    "                dictionary[word] = 0\n",
    "\n",
    "    word_to_id, id_to_word = create_mapping(dictionary)\n",
    "    return dictionary, word_to_id, id_to_word\n",
    "\n",
    "\n",
    "def pad_seq(seq, max_length, PAD_token=0):\n",
    "    \n",
    "    seq += [PAD_token for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "def get_batch(start, batch_size, datas, singletons=[]):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "    chars2_seqs = []\n",
    "\n",
    "    for data in datas[start:start+batch_size]:\n",
    "        # pair is chosen from pairs randomly\n",
    "        words = []\n",
    "        for word in data['words']:\n",
    "            if word in singletons and np.random.uniform() < 0.5:\n",
    "                words.append(1)\n",
    "            else:\n",
    "                words.append(word)\n",
    "        input_seqs.append(data['words'])\n",
    "        target_seqs.append(data['tags'])\n",
    "        chars2_seqs.append(data['chars'])\n",
    "\n",
    "    if input_seqs == []:\n",
    "        return [], [], [], [], [], []\n",
    "    seq_pairs = sorted(zip(input_seqs, target_seqs, chars2_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    input_seqs, target_seqs, chars2_seqs = zip(*seq_pairs)\n",
    "\n",
    "    chars2_seqs_lengths = []\n",
    "    chars2_seqs_padded = []\n",
    "    for chars2 in chars2_seqs:\n",
    "        chars2_lengths = [len(c) for c in chars2]\n",
    "        chars2_padded = [pad_seq(c, max(chars2_lengths)) for c in chars2]\n",
    "        chars2_seqs_padded.append(chars2_padded)\n",
    "        chars2_seqs_lengths.append(chars2_lengths)\n",
    "\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    # input_padded is batch * max_length\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "    target_lengths = [len(s) for s in target_seqs]\n",
    "    assert target_lengths == input_lengths\n",
    "    # target_padded is batch * max_length\n",
    "    target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    return input_padded, input_lengths, target_padded, target_lengths, chars2_seqs_padded, chars2_seqs_lengths\n",
    "\n",
    "\n",
    "def random_batch(batch_size, train_data, singletons=[]):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "    chars2_seqs = []\n",
    "\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # pair is chosen from pairs randomly\n",
    "        data = random.choice(train_data)\n",
    "        words = []\n",
    "        for word in data['words']:\n",
    "            if word in singletons and np.random.uniform() < 0.5:\n",
    "                words.append(1)\n",
    "            else:\n",
    "                words.append(word)\n",
    "        input_seqs.append(data['words'])\n",
    "        target_seqs.append(data['tags'])\n",
    "        chars2_seqs.append(data['chars'])\n",
    "\n",
    "    seq_pairs = sorted(zip(input_seqs, target_seqs, chars2_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    input_seqs, target_seqs, chars2_seqs = zip(*seq_pairs)\n",
    "\n",
    "    chars2_seqs_lengths = []\n",
    "    chars2_seqs_padded = []\n",
    "    for chars2 in chars2_seqs:\n",
    "        chars2_lengths = [len(c) for c in chars2]\n",
    "        chars2_padded = [pad_seq(c, max(chars2_lengths)) for c in chars2]\n",
    "        chars2_seqs_padded.append(chars2_padded)\n",
    "        chars2_seqs_lengths.append(chars2_lengths)\n",
    "\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    # input_padded is batch * max_length\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "    target_lengths = [len(s) for s in target_seqs]\n",
    "    assert target_lengths == input_lengths\n",
    "    # target_padded is batch * max_length\n",
    "    target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    return input_padded, input_lengths, target_padded, target_lengths, chars2_seqs_padded, chars2_seqs_lengths\n",
    "\n",
    "def to_scalar(var):\n",
    "    return var.view(-1).data.tolist()[0]\n",
    "\n",
    "def argmax(vec):\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return to_scalar(idx)\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "class Initializer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def init_embedding(self, input_embedding):\n",
    "        bias = np.sqrt(3.0 / input_embedding.size(1))\n",
    "        nn.init.uniform(input_embedding, -bias, bias)\n",
    "    \n",
    "    def init_linear(self, input_linear):\n",
    "        bias = np.sqrt(6.0 / (input_linear.weight.size(0) + input_linear.weight.size(1)))\n",
    "        nn.init.uniform(input_linear.weight, -bias, bias)\n",
    "        if input_linear.bias is not None:\n",
    "            input_linear.bias.data.zero_()\n",
    "    \n",
    "    def init_lstm(self, input_lstm):\n",
    "        for ind in range(0, input_lstm.num_layers):\n",
    "            weight = eval('input_lstm.weight_ih_l' + str(ind))\n",
    "            bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "            nn.init.uniform(weight, -bias, bias)\n",
    "            weight = eval('input_lstm.weight_hh_l' + str(ind))\n",
    "            bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "            nn.init.uniform(weight, -bias, bias)\n",
    "        \n",
    "        if input_lstm.bidirectional:\n",
    "            for ind in range(0, input_lstm.num_layers):\n",
    "                weight = eval('input_lstm.weight_ih_l' + str(ind) + '_reverse')\n",
    "                bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "                nn.init.uniform(weight, -bias, bias)\n",
    "                weight = eval('input_lstm.weight_hh_l' + str(ind) + '_reverse')\n",
    "                bias = np.sqrt(6.0 / (weight.size(0) / 4 + weight.size(1)))\n",
    "                nn.init.uniform(weight, -bias, bias)\n",
    "        \n",
    "        if input_lstm.bias:\n",
    "            \n",
    "            for ind in range(0, input_lstm.num_layers):\n",
    "                weight = eval('input_lstm.bias_ih_l' + str(ind))\n",
    "                weight.data.zero_()\n",
    "                weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "                weight = eval('input_lstm.bias_hh_l' + str(ind))\n",
    "                weight.data.zero_()\n",
    "                weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "            \n",
    "            if input_lstm.bidirectional:\n",
    "                for ind in range(0, input_lstm.num_layers):\n",
    "                    weight = eval('input_lstm.bias_ih_l' + str(ind) + '_reverse')\n",
    "                    weight.data.zero_()\n",
    "                    weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1\n",
    "                    weight = eval('input_lstm.bias_hh_l' + str(ind) + '_reverse')\n",
    "                    weight.data.zero_()\n",
    "                    weight.data[input_lstm.hidden_size: 2 * input_lstm.hidden_size] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import codecs\n",
    "import cPickle\n",
    "\n",
    "class Loader(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def pad_sequence_cnn(self, chars):\n",
    "        d = {}\n",
    "        chars_length = [len(c) for c in chars]\n",
    "        chars_maxlen = max(chars_length)\n",
    "        chars_mask = np.zeros((len(chars_length), chars_maxlen), dtype='int')\n",
    "        for i, c in enumerate(chars):\n",
    "            chars_mask[i, :chars_length[i]] = c\n",
    "        return chars_mask, chars_length, d\n",
    "    \n",
    "    \n",
    "    def pad_sequence_rnn(self, chars):\n",
    "        chars_sorted = sorted(chars, key=lambda p: len(p), reverse=True)\n",
    "        d = {}\n",
    "        for i, ci in enumerate(chars):\n",
    "            for j, cj in enumerate(chars_sorted):\n",
    "                if ci == cj and not j in d and not i in d.values():\n",
    "                    d[j] = i\n",
    "                    continue\n",
    "        chars_length = [len(c) for c in chars_sorted]\n",
    "        chars_maxlen = max(chars_length)\n",
    "        chars_mask = np.zeros((len(chars_sorted), char_maxlen), dtype='int')\n",
    "        for i, c in enumerate(chars_sorted):\n",
    "            chars_mask[i, :chars_length[i]] = c\n",
    "        return chars_mask, chars_length, d\n",
    "    \n",
    "    def update_tag_scheme(self, sentences, tag_scheme):\n",
    "        \n",
    "        for i, s in enumerate(sentences):\n",
    "            tags = [w[-1] for w in s]\n",
    "            if not iob2(tags):\n",
    "                s_str = '\\n'.join(' '.join(w) for w in s)\n",
    "                raise Exception('Sentences should be given in IOB format! ' +\n",
    "                                'Please check sentence %i:\\n%s' % (i, s_str))\n",
    "            if tag_scheme == 'iob':\n",
    "                for word, new_tag in zip(s, tags):\n",
    "                    word[-1] = new_tag\n",
    "            elif tag_scheme == 'iobes':\n",
    "                new_tags = iob_iobes(tags)\n",
    "                for word, new_tag in zip(s, new_tags):\n",
    "                    word[-1] = new_tag\n",
    "            else:\n",
    "                raise Exception('Unknown tagging scheme!')\n",
    "                \n",
    "    def word_mapping(self, sentences, lower):\n",
    "        \n",
    "        words = [[x[0].lower() if lower else x[0] for x in s] for s in sentences]\n",
    "        dico = create_dico(words)\n",
    "\n",
    "        dico['<PAD>'] = 10000001\n",
    "        dico['<UNK>'] = 10000000\n",
    "        dico = {k:v for k,v in dico.items() if v>=3}\n",
    "        word_to_id, id_to_word = create_mapping(dico)\n",
    "\n",
    "        print(\"Found %i unique words (%i in total)\" % (\n",
    "            len(dico), sum(len(x) for x in words)\n",
    "        ))\n",
    "        return dico, word_to_id, id_to_word\n",
    "    \n",
    "    def load_conll_sentences(self, path, lower, zeros):\n",
    "        \n",
    "        sentences = []\n",
    "        sentence = []\n",
    "        for line in codecs.open(path, 'r', 'utf-8'):\n",
    "            line = zero_digits(line.rstrip()) if zeros else line.rstrip()\n",
    "            if not line:\n",
    "                if len(sentence) > 0:\n",
    "                    if 'DOCSTART' not in sentence[0][0]:\n",
    "                        sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                word = line.split()\n",
    "                assert len(word) >= 2\n",
    "                sentence.append(word)\n",
    "        if len(sentence) > 0:\n",
    "            if 'DOCSTART' not in sentence[0][0]:\n",
    "                sentences.append(sentence)\n",
    "        return sentences\n",
    "    \n",
    "    def load_conll(self, dataset ,parameters):\n",
    "        \n",
    "        zeros = parameters['zeros']\n",
    "        lower = parameters['lower']\n",
    "        word_dim = parameters['wrdim']\n",
    "        pretrained = parameters['ptrnd']\n",
    "        tag_scheme = parameters['tgsch']\n",
    "        \n",
    "        \n",
    "        train_path = os.path.join(dataset,'eng.train')\n",
    "        dev_path = os.path.join(dataset,'eng.testa')\n",
    "        test_path = os.path.join(dataset,'eng.testb')\n",
    "        test_train_path = os.path.join(dataset,'eng.train54019')\n",
    "        \n",
    "        \n",
    "        train_sentences = self.load_conll_sentences(train_path, lower, zeros)\n",
    "        dev_sentences = self.load_conll_sentences(dev_path, lower, zeros)\n",
    "        test_sentences = self.load_conll_sentences(test_path, lower, zeros)\n",
    "        test_train_sentences = self.load_conll_sentences(test_train_path, lower, zeros)\n",
    "        \n",
    "        self.update_tag_scheme(train_sentences, tag_scheme)\n",
    "        self.update_tag_scheme(dev_sentences, tag_scheme)\n",
    "        self.update_tag_scheme(test_sentences, tag_scheme)\n",
    "        self.update_tag_scheme(test_train_sentences, tag_scheme)\n",
    "        \n",
    "        dico_words_train = self.word_mapping(train_sentences, lower)[0]\n",
    "        \n",
    "        all_embedding = 1\n",
    "        dico_words, word_to_id, id_to_word = augment_with_pretrained(\n",
    "                dico_words_train.copy(),\n",
    "                pretrained,\n",
    "                list(itertools.chain.from_iterable(\n",
    "                    [[w[0] for w in s] for s in dev_sentences + test_sentences])\n",
    "                ) if not all_embedding else None)\n",
    "\n",
    "        dico_chars, char_to_id, id_to_char = char_mapping(train_sentences)\n",
    "        dico_tags, tag_to_id, id_to_tag = tag_mapping(train_sentences)\n",
    "        \n",
    "        train_data = prepare_dataset(train_sentences, word_to_id, char_to_id, tag_to_id, lower)\n",
    "        dev_data = prepare_dataset(dev_sentences, word_to_id, char_to_id, tag_to_id, lower)\n",
    "        test_data = prepare_dataset(test_sentences, word_to_id, char_to_id, tag_to_id, lower)\n",
    "        test_train_data = prepare_dataset(test_train_sentences, word_to_id, char_to_id, tag_to_id, lower)\n",
    "        \n",
    "        print(\"%i / %i / %i sentences in train / dev / test.\" % (\n",
    "              len(train_data), len(dev_data), len(test_data)))\n",
    "        \n",
    "        mapping_file = os.path.join(dataset,'mapping.pkl')\n",
    "        \n",
    "        if not os.path.isfile(mapping_file):\n",
    "            all_word_embeds = {}\n",
    "            for i, line in enumerate(codecs.open(pretrained, 'r', 'utf-8')):\n",
    "                s = line.strip().split()\n",
    "                if len(s) == word_dim + 1:\n",
    "                    all_word_embeds[s[0]] = np.array([float(i) for i in s[1:]])\n",
    "\n",
    "            word_embeds = np.random.uniform(-np.sqrt(0.06), np.sqrt(0.06), (len(word_to_id), word_dim))\n",
    "\n",
    "            for w in word_to_id:\n",
    "                if w in all_word_embeds:\n",
    "                    word_embeds[word_to_id[w]] = all_word_embeds[w]\n",
    "                elif w.lower() in all_word_embeds:\n",
    "                    word_embeds[word_to_id[w]] = all_word_embeds[w.lower()]\n",
    "\n",
    "            print('Loaded %i pretrained embeddings.' % len(all_word_embeds))\n",
    "\n",
    "            with open(mapping_file, 'wb') as f:\n",
    "                mappings = {\n",
    "                    'word_to_id': word_to_id,\n",
    "                    'tag_to_id': tag_to_id,\n",
    "                    'id_to_tag': id_to_tag,\n",
    "                    'char_to_id': char_to_id,\n",
    "                    'parameters': parameters,\n",
    "                    'word_embeds': word_embeds\n",
    "                }\n",
    "                cPickle.dump(mappings, f)\n",
    "        else:\n",
    "            mappings = cPickle.load(open(mapping_file,'rb'))\n",
    "            \n",
    "        return train_data, dev_data, test_data, test_train_data, mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "\n",
    "class Evaluator(object):\n",
    "    def __init__(self, result_path, model_name, mappings):\n",
    "        self.result_path = result_path\n",
    "        self.model_name = model_name\n",
    "        self.tag_to_id = mappings['tag_to_id']\n",
    "        self.id_to_tag = mappings['id_to_tag']\n",
    "\n",
    "    def evaluate_conll(self, model, dataset, best_F, eval_script='./datasets/conll/conlleval',\n",
    "                      checkpoint_folder='.'):\n",
    "        \n",
    "        prediction = []\n",
    "        save = False\n",
    "        new_F = 0.0\n",
    "        confusion_matrix = torch.zeros((len(self.tag_to_id) - 2, len(self.tag_to_id) - 2))\n",
    "        for data in dataset:\n",
    "            \n",
    "            sentence = data['words']\n",
    "            tags = data['tags']\n",
    "            chars = data['chars']\n",
    "            caps = data['caps']\n",
    "\n",
    "            words = data['str_words']\n",
    "            \n",
    "            val, out = model.decode(sentence, tags, chars, caps) \n",
    "            \n",
    "            predicted_id = out\n",
    "            ground_truth_id = tags\n",
    "            for (word, true_id, pred_id) in zip(words, ground_truth_id, predicted_id):\n",
    "                line = ' '.join([word, self.id_to_tag[true_id], self.id_to_tag[pred_id]])\n",
    "                prediction.append(line)\n",
    "                confusion_matrix[true_id, pred_id] += 1\n",
    "            prediction.append('')\n",
    "        \n",
    "        predf = os.path.join(self.result_path, self.model_name, checkpoint_folder ,'pred.txt')\n",
    "        scoref = os.path.join(self.result_path, self.model_name, checkpoint_folder ,'score.txt')\n",
    "\n",
    "        with open(predf, 'wb') as f:\n",
    "            f.write('\\n'.join(prediction))\n",
    "\n",
    "        os.system('%s < %s > %s' % (eval_script, predf, scoref))\n",
    "\n",
    "        eval_lines = [l.rstrip() for l in codecs.open(scoref, 'r', 'utf8')]\n",
    "\n",
    "        for i, line in enumerate(eval_lines):\n",
    "            print(line)\n",
    "            if i == 1:\n",
    "                new_F = float(line.strip().split()[-1])\n",
    "                if new_F > best_F:\n",
    "                    best_F = new_F\n",
    "                    save = True\n",
    "                    print('the best F is ', new_F)\n",
    "        '''\n",
    "        print((\"{: >2}{: >7}{: >7}%s{: >9}\" % (\"{: >7}\" * confusion_matrix.size(0))).format(\n",
    "            \"ID\", \"NE\", \"Total\",\n",
    "            *([self.id_to_tag[i] for i in range(confusion_matrix.size(0))] + [\"Percent\"])\n",
    "        ))\n",
    "        for i in range(confusion_matrix.size(0)):\n",
    "            print((\"{: >2}{: >7}{: >7}%s{: >9}\" % (\"{: >7}\" * confusion_matrix.size(0))).format(\n",
    "                str(i), self.id_to_tag[i], str(confusion_matrix[i].sum()),\n",
    "                *([confusion_matrix[i][j] for j in range(confusion_matrix.size(0))] +\n",
    "                  [\"%.3f\" % (confusion_matrix[i][i] * 100. / max(1, confusion_matrix[i].sum()))])\n",
    "            ))\n",
    "        '''\n",
    "        return best_F, new_F, save\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self, model, optimizer, result_path, model_name, usedataset, mappings, eval_every=1):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.eval_every = eval_every\n",
    "        self.model_name = os.path.join(result_path, model_name)\n",
    "        \n",
    "        if usedataset=='conll':\n",
    "            self.evaluator = Evaluator(result_path, model_name, mappings).evaluate_conll\n",
    "    \n",
    "    def adjust_learning_rate(self, optimizer, lr):\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "            \n",
    "    def train_single(self, num_epochs, train_data, dev_data, test_train_data, test_data, learning_rate,\n",
    "                     checkpoint_folder='.', eval_test_train=True, plot_every=1000):\n",
    "        \n",
    "        losses = []\n",
    "        loss = 0.0\n",
    "        best_dev_F = -1.0\n",
    "        best_test_F = -1.0\n",
    "        best_train_F = -1.0\n",
    "        all_F=[[0,0,0]]\n",
    "        count = 0\n",
    "        \n",
    "        self.model.train(True)\n",
    "        for epoch in range(1, num_epochs+1):\n",
    "            t=time.time()\n",
    "            for i, index in enumerate(np.random.permutation(len(train_data))):\n",
    "                \n",
    "                data = train_data[index]\n",
    "                self.model.zero_grad()\n",
    "\n",
    "                sentence = data['words']\n",
    "                tags = data['tags']\n",
    "                chars = data['chars']\n",
    "                caps = data['caps']\n",
    "\n",
    "                score = self.model(sentence, tags, chars, caps)\n",
    "                loss += score.data[0]/len(data['words'])\n",
    "                score.backward()\n",
    "                \n",
    "                nn.utils.clip_grad_norm(self.model.parameters(), 5.0)\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "                if count % plot_every == 0:\n",
    "                    loss /= plot_every\n",
    "                    print(count, ': ', loss)\n",
    "                    if losses == []:\n",
    "                        losses.append(loss)\n",
    "                    losses.append(loss)\n",
    "                    loss = 0.0\n",
    "                    \n",
    "                if count % len(train_data) == 0:\n",
    "                    self.adjust_learning_rate(self.optimizer, lr=learning_rate/(1+0.05*count/len(train_data)))\n",
    "            \n",
    "            if epoch%self.eval_every==0:\n",
    "                \n",
    "                self.model.train(False)\n",
    "                \n",
    "                if eval_test_train:\n",
    "                    best_train_F, new_train_F, _ = self.evaluator(self.model, test_train_data, best_train_F,\n",
    "                                                                 checkpoint_folder=checkpoint_folder)\n",
    "                else:\n",
    "                    best_train_F, new_train_F, _ = 0, 0, 0\n",
    "                best_dev_F, new_dev_F, save = self.evaluator(self.model, dev_data, best_dev_F,\n",
    "                                                            checkpoint_folder=checkpoint_folder)\n",
    "                if save:\n",
    "                    torch.save(self.model, os.path.join(self.model_name, checkpoint_folder, 'modelweights'))\n",
    "                best_test_F, new_test_F, _ = self.evaluator(self.model, test_data, best_test_F,\n",
    "                                                           checkpoint_folder=checkpoint_folder)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "                all_F.append([new_train_F, new_dev_F, new_test_F])\n",
    "                self.model.train(True)\n",
    "\n",
    "            print('*'*80)\n",
    "            print('Epoch %d Complete: Time Taken %d' %(epoch ,time.time() - t))\n",
    "\n",
    "        return losses, all_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7518 unique words (203621 in total)\n",
      "Loading pretrained embeddings from wordvectors/glove.6B.100d.txt...\n",
      "Found 85 unique characters\n",
      "Found 19 unique named entity tags\n",
      "14041 / 3250 / 3453 sentences in train / dev / test.\n",
      "Load Complete\n"
     ]
    }
   ],
   "source": [
    "parameters = OrderedDict()\n",
    "\n",
    "parameters['model'] = opt.usemodel\n",
    "parameters['wrdim'] = opt.worddim\n",
    "parameters['ptrnd'] = opt.pretrnd\n",
    "parameters['rload'] = opt.reload\n",
    "\n",
    "parameters['lower'] = 1\n",
    "parameters['zeros'] = 0\n",
    "parameters['cpdim'] = 0\n",
    "parameters['dpout'] = 0.5\n",
    "parameters['chdim'] = 25\n",
    "parameters['tgsch'] = 'iobes'\n",
    "\n",
    "parameters['wldim'] = 200\n",
    "parameters['cldim'] = 25\n",
    "\n",
    "parameters['wnchl'] = 200\n",
    "parameters['cnchl'] = 25\n",
    "\n",
    "dataset_path = os.path.join('datasets',opt.dataset)\n",
    "result_path = os.path.join(opt.result_path, opt.dataset)\n",
    "model_name = opt.usemodel\n",
    "model_load = opt.reload\n",
    "init_percent = 2\n",
    "acquire_percent = 2\n",
    "acquire_method = 'random'\n",
    "loader = Loader()\n",
    "\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "    \n",
    "if not os.path.exists(os.path.join(result_path, model_name)):\n",
    "    os.makedirs(os.path.join(result_path, model_name))\n",
    "\n",
    "if not os.path.exists(os.path.join(result_path, model_name, 'active_checkpoints', acquire_method)):\n",
    "    os.makedirs(os.path.join(result_path, model_name, 'active_checkpoints', acquire_method))\n",
    "\n",
    "if opt.dataset == 'conll':\n",
    "    train_data, dev_data, test_data, test_train_data, mappings = loader.load_conll(dataset_path, parameters)\n",
    "    \n",
    "word_to_id = mappings['word_to_id']\n",
    "tag_to_id = mappings['tag_to_id']\n",
    "char_to_id = mappings['char_to_id']\n",
    "parameters = mappings['parameters']\n",
    "word_embeds = mappings['word_embeds']\n",
    "\n",
    "print('Load Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, hidden_size, input_dropout_p, output_dropout_p, n_layers, rnn_cell, max_len=25):\n",
    "        super(baseRNN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.input_dropout_p = input_dropout_p\n",
    "        self.output_dropout_p = output_dropout_p\n",
    "        \n",
    "        if rnn_cell.lower() == 'lstm':\n",
    "            self.rnn_cell = nn.LSTM\n",
    "        elif rnn_cell.lower() == 'gru':\n",
    "            self.rnn_cell = nn.GRU\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported RNN Cell: {0}\".format(rnn_cell))\n",
    "\n",
    "        self.input_dropout = nn.Dropout(p=input_dropout_p)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "class CharEncoderCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_size ,out_channels, kernel_width, pad_width, \n",
    "                 input_dropout_p=0, output_dropout_p=0, in_channels=1):\n",
    "        \n",
    "        super(CharEncoderCNN, self).__init__()\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        self.input_dropout = nn.Dropout(input_dropout_p)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.cnn = nn.Conv2d(in_channels, out_channels, kernel_size = (kernel_width, embedding_size),\n",
    "                             padding = (pad_width,0))\n",
    "\n",
    "    def forward(self, input_var, input_lengths=None):\n",
    "        \n",
    "        embedded = self.embedding(input_var).unsqueeze(1)\n",
    "        embedded = self.input_dropout(embedded)\n",
    "        \n",
    "        output = self.cnn(embedded)\n",
    "        output = nn.functional.max_pool2d(output, kernel_size=(output.size(2), 1)).view(output.size(0),self.out_channels)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class WordEncoderRNN(baseRNN):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_size ,hidden_size, char_size, cap_size=0, input_dropout_p=0.5, \n",
    "                 output_dropout_p=0, n_layers=1, bidirectional=True, rnn_cell='lstm'):\n",
    "        \n",
    "        super(WordEncoderRNN, self).__init__(vocab_size, hidden_size, input_dropout_p, \n",
    "                                             output_dropout_p, n_layers, rnn_cell)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        augmented_embedding_size = embedding_size + char_size + cap_size\n",
    "        self.rnn = self.rnn_cell(augmented_embedding_size, hidden_size, n_layers,\n",
    "                                 bidirectional=bidirectional, dropout=output_dropout_p)\n",
    "\n",
    "    def forward(self, sentence, char_embedding, cap_embedding=None ,input_lengths=None):\n",
    "        \n",
    "        embedded = self.embedding(sentence)\n",
    "        if cap_embedding:\n",
    "            embedded = torch.cat((embedded,char_embedding,cap_embedding),1)  \n",
    "        else:\n",
    "            embedded = torch.cat((embedded,char_embedding),1)\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        embedded = self.input_dropout(embedded)\n",
    "        \n",
    "        output, _ = self.rnn(embedded)\n",
    "        output = output.view(len(sentence), self.hidden_size*2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class DecoderCRF(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dimension, tag_to_ix, input_dropout_p=0.5):\n",
    "        \n",
    "        super(DecoderCRF, self).__init__()\n",
    "        \n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "        \n",
    "        self.dropout = nn.Dropout(input_dropout_p)\n",
    "        self.hidden2tag = nn.Linear(input_dimension, self.tagset_size)\n",
    "        \n",
    "        self.transitions = nn.Parameter(torch.zeros(self.tagset_size, self.tagset_size))\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "    \n",
    "    def viterbi_decode(self, features):\n",
    "        \n",
    "        backpointers = []\n",
    "        \n",
    "        init_vars = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
    "        init_vars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "        forward_var = Variable(init_vars).cuda()\n",
    "        \n",
    "        for feat in features:\n",
    "            next_tag_var = forward_var.view(1, -1).expand(self.tagset_size, \n",
    "                                      self.tagset_size) + self.transitions\n",
    "            _, bptrs_t = torch.max(next_tag_var, dim=1)\n",
    "            \n",
    "            bptrs_t = bptrs_t.squeeze().data.cpu().numpy()\n",
    "            next_tag_var = next_tag_var.data.cpu().numpy()\n",
    "            \n",
    "            viterbivars_t = next_tag_var[range(len(bptrs_t)), bptrs_t]\n",
    "            viterbivars_t = Variable(torch.FloatTensor(viterbivars_t)).cuda()\n",
    "            \n",
    "            forward_var = viterbivars_t + feat\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        terminal_var.data[self.tag_to_ix[STOP_TAG]] = -10000.\n",
    "        terminal_var.data[self.tag_to_ix[START_TAG]] = -10000.\n",
    "        \n",
    "        best_tag_id = argmax(terminal_var.unsqueeze(0))\n",
    "        path_score = terminal_var[best_tag_id]\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        start = best_path.pop()\n",
    "        \n",
    "        assert start == self.tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        \n",
    "        return path_score, best_path\n",
    "    \n",
    "    def crf_forward(self, feats):\n",
    "        \n",
    "        init_alphas = torch.Tensor(1, self.tagset_size).fill_(-10000.)\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "        forward_var = Variable(init_alphas).cuda()\n",
    "        \n",
    "        for feat in feats:\n",
    "            emit_score = feat.view(-1, 1)\n",
    "            tag_var = forward_var + self.transitions + emit_score\n",
    "            max_tag_var, _ = torch.max(tag_var, dim=1)\n",
    "            tag_var = tag_var - max_tag_var.view(-1, 1)\n",
    "            forward_var = max_tag_var + torch.log(torch.sum(torch.exp(tag_var), dim=1)).view(1, -1)\n",
    "            \n",
    "        terminal_var = (forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]).view(1, -1)\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def score_sentence(self, features, tags):\n",
    "        \n",
    "        r = torch.LongTensor(range(features.size()[0])).cuda()\n",
    "        pad_start_tags = torch.cat([torch.cuda.LongTensor([self.tag_to_ix[START_TAG]]), tags])\n",
    "        pad_stop_tags = torch.cat([tags, torch.cuda.LongTensor([self.tag_to_ix[STOP_TAG]])])\n",
    "\n",
    "        score = torch.sum(self.transitions[pad_stop_tags, pad_start_tags]) + torch.sum(features[r, tags])\n",
    "        return score\n",
    "    \n",
    "    def decode(self, input_var, tags, input_lengths=None):\n",
    "        \n",
    "        input_var = self.dropout(input_var)\n",
    "        features = self.hidden2tag(input_var)\n",
    "        score, tag_seq = self.viterbi_decode(features)\n",
    "        \n",
    "        return score, tag_seq\n",
    "    \n",
    "    def forward(self, input_var, tags, input_lengths=None):\n",
    "        \n",
    "        input_var = self.dropout(input_var)\n",
    "        features = self.hidden2tag(input_var)\n",
    "        forward_score = self.crf_forward(features)\n",
    "        ground_score = self.score_sentence(features, tags)\n",
    "        \n",
    "        return forward_score-ground_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_BiLSTM_CRF(nn.Module):\n",
    "    \n",
    "    def __init__(self, word_vocab_size, word_embedding_dim, word_hidden_dim, char_vocab_size,\n",
    "                 char_embedding_dim, char_out_channels, tag_to_id, cap_input_dim=0 ,cap_embedding_dim=0, \n",
    "                 pretrained=None):\n",
    "        \n",
    "        super(CNN_BiLSTM_CRF, self).__init__()\n",
    "        \n",
    "        self.word_vocab_size = word_vocab_size\n",
    "        self.word_embedding_dim = word_embedding_dim\n",
    "        self.word_hidden_dim = word_hidden_dim\n",
    "        \n",
    "        self.char_vocab_size = char_vocab_size\n",
    "        self.char_embedding_dim = char_embedding_dim\n",
    "        self.char_out_channels = char_out_channels\n",
    "        \n",
    "        self.cap_input_dim = cap_input_dim\n",
    "        self.cap_embedding_dim = cap_embedding_dim\n",
    "        \n",
    "        self.tag_to_ix = tag_to_id\n",
    "        self.tagset_size = len(tag_to_id)\n",
    "        \n",
    "        self.initializer = Initializer()\n",
    "        self.loader = Loader()\n",
    "        \n",
    "        if self.cap_input_dim and self.cap_embedding_dim:\n",
    "            self.cap_embedder = nn.Embedding(self.cap_input_dim, self.cap_embedding_dim)\n",
    "            self.initializer.init_embedding(self.cap_embedder.weight)\n",
    "        \n",
    "        self.char_encoder = CharEncoderCNN(char_vocab_size, char_embedding_dim, char_out_channels, \n",
    "                                           kernel_width=3, pad_width=2)\n",
    "        \n",
    "        self.initializer.init_embedding(self.char_encoder.embedding.weight)\n",
    "        \n",
    "        self.word_encoder = WordEncoderRNN(word_vocab_size, word_embedding_dim ,word_hidden_dim, \n",
    "                                           char_out_channels, input_dropout_p=0.5)\n",
    "        \n",
    "        if pretrained is not None:\n",
    "            self.word_encoder.embedding.weight = nn.Parameter(torch.FloatTensor(pretrained))\n",
    "            \n",
    "        self.initializer.init_lstm(self.word_encoder.rnn)\n",
    "        \n",
    "        self.decoder = DecoderCRF(word_hidden_dim*2, self.tag_to_ix)\n",
    "        self.initializer.init_linear(self.decoder.hidden2tag)\n",
    "        \n",
    "    def forward(self, sentence, tags, chars, caps):\n",
    "        \n",
    "        sentence = Variable(torch.LongTensor(sentence)).cuda()\n",
    "        tags = torch.LongTensor(tags).cuda()\n",
    "        caps = Variable(torch.LongTensor(caps)).cuda()\n",
    "        \n",
    "        chars_mask, _, _ = self.loader.pad_sequence_cnn(chars)\n",
    "        chars_mask = Variable(torch.LongTensor(chars_mask)).cuda()\n",
    "        \n",
    "        if self.cap_input_dim and self.cap_embedding_dim:\n",
    "            cap_features = self.cap_embedder(caps)\n",
    "        else:\n",
    "            cap_features = None\n",
    "            \n",
    "        char_features = self.char_encoder(chars_mask) \n",
    "        word_features = self.word_encoder(sentence, char_features, cap_features)\n",
    "        \n",
    "        score = self.decoder(word_features, tags)\n",
    "        \n",
    "        return score\n",
    "    \n",
    "    def decode(self, sentence, tags, chars, caps):\n",
    "        \n",
    "        sentence = Variable(torch.LongTensor(sentence)).cuda()\n",
    "        tags = torch.LongTensor(tags).cuda()\n",
    "        caps = Variable(torch.LongTensor(caps))\n",
    "        \n",
    "        chars_mask, _, _ = self.loader.pad_sequence_cnn(chars)\n",
    "        chars_mask = Variable(torch.LongTensor(chars_mask)).cuda()\n",
    "        \n",
    "        if self.cap_input_dim and self.cap_embedding_dim:\n",
    "            cap_features = self.cap_embedder(caps)\n",
    "        else:\n",
    "            cap_features = None\n",
    "            \n",
    "        char_features = self.char_encoder(chars_mask) \n",
    "        word_features = self.word_encoder(sentence, char_features, cap_features)\n",
    "        \n",
    "        score,tag_seq = self.decoder.decode(word_features, tags)\n",
    "        \n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Acquisition(object):\n",
    "    def __init__(self, train_data, init_percent=2, seed=0):\n",
    "        self.tokenlen = sum([len(x['words']) for x in train_data])\n",
    "        self.train_index = set()\n",
    "        self.npr = np.random.RandomState(seed)\n",
    "        self.obtain_data(train_data, acquire = init_percent)\n",
    "        \n",
    "    def get_random(self, data, num_tokens):\n",
    "        print('random')\n",
    "        test_indices = self.npr.permutation(len(data))\n",
    "        cur_tokens=0\n",
    "        cur_indices = set()\n",
    "        i = 0\n",
    "        while cur_tokens<num_tokens:\n",
    "            if test_indices[i] not in self.train_index:\n",
    "                cur_indices.add(test_indices[i])\n",
    "                cur_tokens += len(data[test_indices[i]]['words'])\n",
    "            i+=1\n",
    "        self.train_index.update(cur_indices)\n",
    "                 \n",
    "    def get_mnlp(self, data, model_path, decoder, num_tokens):\n",
    "        print('mnlp')\n",
    "        model = torch.load(model_path)\n",
    "        probs = np.ones(len(dataset))*float('Inf')\n",
    "        for j, data in enumerate(dataset):\n",
    "            if j not in self.train_index:\n",
    "                sentence = data['words']\n",
    "                tags = data['tags']\n",
    "                chars = data['chars']\n",
    "                caps = data['caps']\n",
    "                if decoder=='CRF':\n",
    "                    score, _ = model.decode(sentence, tags, chars, caps)\n",
    "                elif decoder=='LSTM':\n",
    "                    raise NotImplementedError()\n",
    "                else:\n",
    "                    raise NotImplementedError()\n",
    "                probs[j] = score/len(sentence)\n",
    "        test_indices = np.argsort(probs)\n",
    "        cur_tokens=0\n",
    "        cur_indices = set()\n",
    "        i = 0\n",
    "        while cur_tokens<num_tokens:\n",
    "            cur_indices.add(test_indices[i])\n",
    "            cur_tokens += len(dataset[test_indices[i]]['words'])\n",
    "            i+=1\n",
    "        self.train_index.update(cur_indices)\n",
    "        \n",
    "    def get_bald(self, data, model_path, num_tokens, num_samples=10):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def obtain_data(self, data, model_path=None, model_name=None, acquire=2, method='random', num_samples=10):\n",
    "        num_tokens = (acquire*self.tokenlen)/100\n",
    "        if model_path is None or model_name is None:\n",
    "            method = 'random'\n",
    "        \n",
    "        if method=='random':\n",
    "            self.get_random(data, num_tokens)\n",
    "        else:\n",
    "            decoder = model_name.split('_')[2]\n",
    "            if method=='mnlp':\n",
    "                self.get_mnlp(data, model_path, decoder, num_tokens)\n",
    "            elif method=='bald':\n",
    "                self.get_bald(data, model_path, decoder, num_tokens, num_samples)\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_BiLSTM_CRF(\n",
       "  (char_encoder): CharEncoderCNN(\n",
       "    (input_dropout): Dropout(p=0)\n",
       "    (embedding): Embedding(85, 25)\n",
       "    (cnn): Conv2d(1, 25, kernel_size=(3, 25), stride=(1, 1), padding=(2, 0))\n",
       "  )\n",
       "  (word_encoder): WordEncoderRNN(\n",
       "    (input_dropout): Dropout(p=0.5)\n",
       "    (embedding): Embedding(400176, 100)\n",
       "    (rnn): LSTM(125, 200, bidirectional=True)\n",
       "  )\n",
       "  (decoder): DecoderCRF(\n",
       "    (dropout): Dropout(p=0.5)\n",
       "    (hidden2tag): Linear(in_features=400, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vocab_size = len(word_to_id)\n",
    "word_embedding_dim = parameters['wrdim']\n",
    "word_hidden_dim = parameters['wldim']\n",
    "char_vocab_size = len(char_to_id)\n",
    "char_embedding_dim = parameters['chdim']\n",
    "char_out_channels = parameters['cnchl']\n",
    "\n",
    "model = CNN_BiLSTM_CRF(word_vocab_size, word_embedding_dim, word_hidden_dim, char_vocab_size,\n",
    "                       char_embedding_dim, char_out_channels, tag_to_id, pretrained = word_embeds)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = sum([len(x['words']) for x in train_data])\n",
    "avail_budget = total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random\n",
      "26 :  1.82299238996\n",
      "52 :  1.08773848551\n",
      "78 :  1.14651875938\n",
      "104 :  1.06048175351\n",
      "130 :  0.960336463056\n",
      "156 :  1.16259908724\n",
      "182 :  0.67661666933\n",
      "208 :  0.783190603303\n",
      "234 :  0.751809190956\n",
      "260 :  1.00344730598\n",
      "processed 51362 tokens with 5938 phrases; found: 2717 phrases; correct: 1792.\n",
      "accuracy:  87.32%; precision:  65.96%; recall:  30.18%; FB1:  41.41\n",
      "the best F is  41.41\n",
      "              LOC: precision:  57.37%; recall:  40.66%; FB1:  47.59  1302\n",
      "             MISC: precision:  17.14%; recall:   0.65%; FB1:   1.26  35\n",
      "              ORG: precision:  73.44%; recall:  24.53%; FB1:  36.78  448\n",
      "              PER: precision:  76.18%; recall:  38.55%; FB1:  51.19  932\n",
      "processed 46435 tokens with 5628 phrases; found: 2981 phrases; correct: 1809.\n",
      "accuracy:  86.73%; precision:  60.68%; recall:  32.14%; FB1:  42.03\n",
      "the best F is  42.03\n",
      "              LOC: precision:  50.11%; recall:  41.34%; FB1:  45.30  1371\n",
      "             MISC: precision:   8.33%; recall:   0.29%; FB1:   0.56  24\n",
      "              ORG: precision:  65.48%; recall:  29.89%; FB1:  41.04  756\n",
      "              PER: precision:  75.30%; recall:  38.65%; FB1:  51.08  830\n",
      "********************************************************************************\n",
      "Epoch 1 Complete: Time Taken 49\n",
      "lc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/ipykernel/__main__.py:73: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Budget Exhausted: 8151, Best F on Validation 41.410, Best F on Test 42.030\n",
      "********************************************************************************\n",
      "206 :  0.802931896267\n",
      "412 :  0.614739345636\n",
      "618 :  0.358415533361\n",
      "824 :  0.52116406481\n",
      "1030 :  0.434526739305\n",
      "1236 :  0.329451438324\n",
      "1442 :  0.326820639677\n",
      "1648 :  0.279131413317\n",
      "1854 :  0.242813328826\n",
      "2060 :  0.249011093972\n",
      "processed 51362 tokens with 5938 phrases; found: 3445 phrases; correct: 2707.\n",
      "accuracy:  90.34%; precision:  78.58%; recall:  45.59%; FB1:  57.70\n",
      "the best F is  57.7\n",
      "              LOC: precision:  88.47%; recall:  54.71%; FB1:  67.61  1136\n",
      "             MISC: precision:  52.07%; recall:   9.59%; FB1:  16.19  169\n",
      "              ORG: precision:  61.84%; recall:  43.03%; FB1:  50.75  933\n",
      "              PER: precision:  85.92%; recall:  56.30%; FB1:  68.02  1207\n",
      "processed 46435 tokens with 5628 phrases; found: 3575 phrases; correct: 2702.\n",
      "accuracy:  90.26%; precision:  75.58%; recall:  48.01%; FB1:  58.72\n",
      "the best F is  58.72\n",
      "              LOC: precision:  85.09%; recall:  56.98%; FB1:  68.25  1113\n",
      "             MISC: precision:  31.28%; recall:   8.80%; FB1:  13.74  195\n",
      "              ORG: precision:  65.73%; recall:  46.44%; FB1:  54.42  1170\n",
      "              PER: precision:  84.32%; recall:  57.20%; FB1:  68.17  1097\n",
      "********************************************************************************\n",
      "Epoch 1 Complete: Time Taken 90\n",
      "lc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-bd3ea705ee1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     acquisition_function.obtain_data(model_path = os.path.join(checkpoint_path ,'modelweights'), model_name = model_name,\n\u001b[0;32m---> 24\u001b[0;31m                                      data = train_data, acquire = acquire_percent, method='lc')\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'acquisition2.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-f2e05ef3f341>\u001b[0m in \u001b[0;36mobtain_data\u001b[0;34m(self, data, model_path, model_name, acquire, method, num_samples)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'lc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'mnlp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-f2e05ef3f341>\u001b[0m in \u001b[0;36mget_lc\u001b[0;34m(self, dataset, model_path, decoder, num_tokens)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'caps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'CRF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                     \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-c3acd8df5ef8>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, sentence, tags, chars, caps)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mcap_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mchar_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mword_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-104-3a5d2f36e293>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_var, input_lengths)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/nn/modules/sparse.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/nn/_functions/thnn/sparse.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4463b517d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acquisition_function = Acquisition(train_data, init_percent=init_percent, seed=0)\n",
    "learning_rate = 0.015\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "trainer = Trainer(model, optimizer, result_path, model_name, usedataset=opt.dataset, mappings= mappings)\n",
    "\n",
    "active_train_data = [train_data[i] for i in acquisition_function.train_index]\n",
    "tokens_acquired = sum([len(x['words']) for x in active_train_data])\n",
    "\n",
    "while tokens_acquired < avail_budget:\n",
    "    \n",
    "    checkpoint_folder = os.path.join('active_checkpoint',acquire_method, str(tokens_acquired).zfill(8))\n",
    "    checkpoint_path = os.path.join(result_path, model_name, checkpoint_folder)\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "        \n",
    "    losses, all_F = trainer.train_single(1, active_train_data, dev_data, test_train_data, test_data,\n",
    "                                        learning_rate = learning_rate, checkpoint_folder = checkpoint_folder,\n",
    "                                        plot_every = len(acquisition_function.train_index)/10,eval_test_train=False)\n",
    "    \n",
    "    pkl.dump(acquisition_function, open(os.path.join(checkpoint_path,'acquisition1.p'),'wb'))\n",
    "    \n",
    "    acquisition_function.obtain_data(model_path = os.path.join(checkpoint_path ,'modelweights'), model_name = model_name,\n",
    "                                     data = train_data, acquire = acquire_percent, method='lc')\n",
    "    \n",
    "    pkl.dump(acquisition_function, open(os.path.join(checkpoint_path,'acquisition2.p'),'wb'))\n",
    "    \n",
    "    active_train_data = [train_data[i] for i in acquisition_function.train_index]\n",
    "    tokens_acquired = sum([len(x['words']) for x in active_train_data])\n",
    "    \n",
    "    print ('*'*80)\n",
    "    saved_epoch = np.argmax(np.array([item[1] for item in all_F]))\n",
    "    print ('Budget Exhausted: %d, Best F on Validation %.3f, Best F on Test %.3f' %(tokens_acquired,\n",
    "                                        all_F[saved_epoch][1], all_F[saved_epoch][2]))\n",
    "    print ('*'*80)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(losses)\n",
    "    plt.savefig(os.path.join(checkpoint_path,'lossplot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p27]",
   "language": "python",
   "name": "conda-env-pytorch_p27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
